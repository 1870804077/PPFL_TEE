import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import copy
import gc
import random
import os
import json

import os
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

from model.Lenet5 import LeNet5
from model.Cifar10Net import CIFAR10Net
from _utils_.LSH_proj_extra import SuperBitLSH
from _utils_.poison_loader import PoisonLoader
from defence.score import ScoreCalculator
from defence.kickout import KickoutManager
from _utils_.dataloader import load_and_split_dataset
from _utils_.save_config import *

# è®¾å¤‡é…ç½®
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Client:
    def __init__(self, client_id, dataloader, model_class, poison_loader=None):
        self.client_id = client_id
        self.dataloader = dataloader
        self.model_class = model_class
        self.poison_loader = poison_loader or PoisonLoader()
        self.model = None
        self.optimizer = None
        self.superbit_lsh = SuperBitLSH()

    def receive_model_and_proj(self, model_params, projection_matrix_path):
        """æ¥æ”¶æœåŠ¡ç«¯çš„æ¨¡å‹å‚æ•°å’ŒæŠ•å½±çŸ©é˜µæ–‡ä»¶è·¯å¾„"""
        if self.model is None:
            self.model = self.model_class().to(DEVICE)
        self.model.load_state_dict(model_params)
        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)
        self.superbit_lsh.set_projection_matrix_path(projection_matrix_path)

    def local_train(self):
        """æœ¬åœ°è®­ç»ƒå¹¶è¿”å›æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦"""
        # ä½¿ç”¨PoisonLoaderæ‰§è¡Œæ”»å‡»
        if self.poison_loader is not None and self.poison_loader.attack_methods:
            # æ¶æ„å®¢æˆ·ç«¯ï¼šæ‰§è¡ŒæŒ‡å®šçš„æ”»å‡»
            trained_params, grad_flat = self.poison_loader.execute_attack(
                self.model, self.dataloader, self.model_class, DEVICE, self.optimizer
            )
        else:
            # æ­£å¸¸å®¢æˆ·ç«¯ï¼šæ‰§è¡Œæ ‡å‡†è®­ç»ƒ
            import torch.nn as nn
            import copy
            import gc
            
            self.model.train()
            initial_params = copy.deepcopy(self.model.state_dict())
            initial_model = self.model_class().to(DEVICE)
            initial_model.load_state_dict(initial_params)

            criterion = nn.CrossEntropyLoss()
            for epoch in range(5):  # LOCAL_EPOCHS
                for data, target in self.dataloader:
                    data, target = data.to(DEVICE), target.to(DEVICE)

                    self.optimizer.zero_grad()
                    output = self.model(data)
                    loss = criterion(output, target)
                    loss.backward()
                    self.optimizer.step()

            # è®¡ç®—æ¢¯åº¦ - åªå¯¹æµ®ç‚¹å‚æ•°è®¡ç®—æ¢¯åº¦
            initial_flat = initial_model.get_flat_params()
            trained_flat = self.model.get_flat_params()
            grad_flat = trained_flat - initial_flat

            # é‡Šæ”¾å†…å­˜
            del initial_model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # åº”ç”¨æ¢¯åº¦æŠ•æ¯’
            grad_flat = self.poison_loader.apply_gradient_poison(grad_flat)

            # è¿”å›è®­ç»ƒåçš„å‚æ•°å’Œæ¢¯åº¦
            trained_params = copy.deepcopy(self.model.state_dict())
        
        return trained_params, grad_flat


    def extract_gradient_feature(self, grad_flat):
        """æå–æ¢¯åº¦ç‰¹å¾"""
        feature = self.superbit_lsh.extract_feature(grad_flat, batch_size=512)  # åˆ†æ‰¹å¤„ç†
        # åº”ç”¨ç‰¹å¾æŠ•æ¯’
        feature = self.poison_loader.apply_feature_poison(feature)

        # é‡Šæ”¾æ¢¯åº¦å†…å­˜
        del grad_flat
        gc.collect()

        return feature


class Server:
    def __init__(self, model, detection_method="lsh_score_kickout", seed=42):
        """æœåŠ¡ç«¯ç±»"""
        self.global_model = model.to(DEVICE)
        self.superbit_lsh = SuperBitLSH(seed=seed)
        self.projection_matrix_path = None
        self.client_models = []
        self.client_data_sizes = []
        self.client_features = []
        self.client_ids = []
        self.detection_method = detection_method
        self.seed = seed 
        
        # æ ¹æ®æ£€æµ‹æ–¹æ³•åˆå§‹åŒ–ç»„ä»¶
        if self.detection_method in ["lsh_score_kickout", "only_score"]:
            self.score_calculator = ScoreCalculator()
        if self.detection_method in ["lsh_score_kickout", "only_kickout"]:
            self.kickout_manager = KickoutManager()

    def generate_projection_matrix(self, input_dim, output_dim, matrix_file_path=None):
        """ç”ŸæˆæŠ•å½±çŸ©é˜µå¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œä½¿ç”¨projæ–‡ä»¶å¤¹
        if matrix_file_path is None:
            matrix_file_path = f"proj/projection_matrix_{input_dim}x{output_dim}.pt"
        
        self.projection_matrix_path = self.superbit_lsh.generate_projection_matrix(
            input_dim, output_dim, device='cpu', matrix_file_path=matrix_file_path
        )

    def send_model_and_proj(self):
        """å‘é€æ¨¡å‹å‚æ•°å’ŒæŠ•å½±çŸ©é˜µæ–‡ä»¶è·¯å¾„"""
        return copy.deepcopy(self.global_model.state_dict()), self.projection_matrix_path

    def receive_client_data(self, model_params, data_size, feature, client_id):
        """æ¥æ”¶å®¢æˆ·ç«¯æ•°æ®"""
        self.client_models.append(model_params)
        self.client_data_sizes.append(data_size)
        self.client_features.append(feature)
        self.client_ids.append(client_id)

    def aggregate_without_detection(self):
        """ä¸å¸¦æ£€æµ‹çš„èšåˆï¼ˆFedAvgï¼‰"""
        if not self.client_models:
            return

        total_data_size = sum(self.client_data_sizes)
        if total_data_size == 0:
            return

        # è·å–ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°ä½œä¸ºæ¨¡æ¿
        first_params = self.client_models[0]
        agg_params = {}
        
        for key, param in first_params.items():
            # ç¡®ä¿èšåˆå‚æ•°çš„æ•°æ®ç±»å‹ä¸åŸå§‹å‚æ•°å®Œå…¨ä¸€è‡´
            agg_params[key] = torch.zeros_like(param, dtype=param.dtype, device=param.device)

        for i, params in enumerate(self.client_models):
            weight = self.client_data_sizes[i] / total_data_size
            for key in agg_params.keys():
                # ç¡®ä¿æƒé‡å’Œå‚æ•°çš„æ•°æ®ç±»å‹åŒ¹é…
                client_param = params[key].to(agg_params[key].device)
                
                # å¦‚æœå‚æ•°æ˜¯æ•´æ•°ç±»å‹ï¼ˆLong, Intç­‰ï¼‰ï¼Œæƒé‡éœ€è¦è½¬æ¢ä¸ºåˆé€‚çš„ç±»å‹
                if agg_params[key].dtype in [torch.long, torch.int, torch.short, torch.int8, torch.uint8]:
                    # å¯¹äºæ•´æ•°å‚æ•°ï¼Œç›´æ¥ç›¸åŠ æˆ–æ ¹æ®éœ€è¦è¿›è¡Œç‰¹æ®Šå¤„ç†
                    # ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæ•´æ•°å‚æ•°ä¸åº”è¯¥å‚ä¸åŠ æƒå¹³å‡ï¼Œå®ƒä»¬é€šå¸¸æ˜¯ç´¢å¼•æˆ–è®¡æ•°
                    # è¿™é‡Œæˆ‘ä»¬è·³è¿‡æ•´æ•°å‚æ•°çš„èšåˆï¼Œåªèšåˆæµ®ç‚¹å‚æ•°
                    continue
                else:
                    # å¯¹äºæµ®ç‚¹å‚æ•°ï¼Œè¿›è¡Œæ­£å¸¸çš„åŠ æƒèšåˆ
                    agg_params[key] += client_param.float() * float(weight)

        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(agg_params)
        self._clear_client_data()

    def aggregate_with_detection(self):
        """å¸¦æ£€æµ‹çš„èšåˆ"""
        if not self.client_models:
            return

        # è·å–ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°ä½œä¸ºæ¨¡æ¿
        first_params = self.client_models[0]
        agg_params = {}
        
        for key, param in first_params.items():
            # ç¡®ä¿èšåˆå‚æ•°çš„æ•°æ®ç±»å‹ä¸åŸå§‹å‚æ•°å®Œå…¨ä¸€è‡´
            agg_params[key] = torch.zeros_like(param, dtype=param.dtype, device=param.device)

        if self.detection_method == "lsh_score_kickout":
            # å®Œæ•´æµç¨‹ï¼šæ‰“åˆ† + å‰”é™¤
            client_scores = {}
            for i, client_id in enumerate(self.client_ids):
                client_scores[client_id] = self.score_calculator.calculate_scores(
                    client_id, self.client_features[i], self.client_data_sizes[i]
                )
            weights = self.kickout_manager.determine_weights(client_scores)
            
            for i, (client_id, params) in enumerate(zip(self.client_ids, self.client_models)):
                weight = weights.get(client_id, 0.0)
                if weight > 0:
                    for key in agg_params.keys():
                        # ç¡®ä¿æƒé‡å’Œå‚æ•°çš„æ•°æ®ç±»å‹åŒ¹é…
                        client_param = params[key].to(agg_params[key].device)
                        
                        # åªå¯¹æµ®ç‚¹å‚æ•°è¿›è¡ŒåŠ æƒèšåˆ
                        if agg_params[key].dtype in [torch.long, torch.int, torch.short, torch.int8, torch.uint8]:
                            continue
                        else:
                            agg_params[key] += client_param.float() * float(weight)
        
        elif self.detection_method == "only_score":
            # ä»…æ‰“åˆ†ï¼ˆæƒé‡=åˆ†æ•°ï¼Œä¸å‰”é™¤ï¼‰
            client_scores = {}
            for i, client_id in enumerate(self.client_ids):
                client_scores[client_id] = self.score_calculator.calculate_scores(
                    client_id, self.client_features[i], self.client_data_sizes[i]
                )
            total_score = sum([s['final_score'] for s in client_scores.values()])
            weights = {cid: s['final_score']/total_score for cid, s in client_scores.items()}
            
            for i, (client_id, params) in enumerate(zip(self.client_ids, self.client_models)):
                weight = weights.get(client_id, 0.0)
                for key in agg_params.keys():
                    client_param = params[key].to(agg_params[key].device)
                    
                    # åªå¯¹æµ®ç‚¹å‚æ•°è¿›è¡ŒåŠ æƒèšåˆ
                    if agg_params[key].dtype in [torch.long, torch.int, torch.short, torch.int8, torch.uint8]:
                        continue
                    else:
                        agg_params[key] += client_param.float() * float(weight)
        
        elif self.detection_method == "only_kickout":
            # ä»…å‰”é™¤ï¼ˆæŒ‰å›ºå®šé˜ˆå€¼ï¼Œä¸æ‰“åˆ†ï¼‰
            threshold = 1.0 / len(self.client_ids)
            weights = {}
            total_data = sum(self.client_data_sizes)
            for i, client_id in enumerate(self.client_ids):
                data_ratio = self.client_data_sizes[i] / total_data
                weights[client_id] = data_ratio if data_ratio >= threshold else 0.0
            
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {cid: w/total_weight for cid, w in weights.items()}
            
            for i, (client_id, params) in enumerate(zip(self.client_ids, self.client_models)):
                weight = weights.get(client_id, 0.0)
                if weight > 0:
                    for key in agg_params.keys():
                        client_param = params[key].to(agg_params[key].device)
                        
                        # åªå¯¹æµ®ç‚¹å‚æ•°è¿›è¡ŒåŠ æƒèšåˆ
                        if agg_params[key].dtype in [torch.long, torch.int, torch.short, torch.int8, torch.uint8]:
                            continue
                        else:
                            agg_params[key] += client_param.float() * float(weight)

        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(agg_params)
        self._clear_client_data()

    def _clear_client_data(self):
        """æ¸…ç©ºå®¢æˆ·ç«¯æ•°æ®"""
        self.client_models = []
        self.client_data_sizes = []
        self.client_features = []
        self.client_ids = []

    def evaluate_model(self, test_loader):
        """è¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡"""
        self.global_model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(DEVICE), target.to(DEVICE)
                outputs = self.global_model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()

        accuracy = 100 * correct / total
        return accuracy

def run_single_mode(model_type, dataset_type, config, mode_name, detection_method, seed):
    """è¿è¡Œå•ä¸ªè®­ç»ƒæ¨¡å¼"""
    # æ£€æŸ¥ç»“æœæ˜¯å¦å·²å­˜åœ¨ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼šé¿å…é‡å¤è®­ç»ƒï¼‰
    exists, acc_history = check_result_exists(
        save_dir="results",
        mode_name=mode_name,
        model_type=model_type,
        dataset_type=dataset_type,
        detection_method=detection_method,
        config=config
    )
    print(f"exists: {exists}")
    if exists:
        return np.array(acc_history)

    # åŠ è½½æ•°æ®é›†
    all_client_dataloaders, test_loader = load_and_split_dataset(
        dataset_name=dataset_type,
        num_clients=config['total_clients'],
        batch_size=config['batch_size'],
        if_noniid=config['if_noniid'],
        alpha=config['alpha'],
        data_dir="./data"
    )

    # é€‰æ‹©æ¨¡å‹
    model_class = LeNet5 if model_type == 'lenet5' else CIFAR10Net

    # åˆå§‹åŒ–æœåŠ¡ç«¯
    init_model = model_class()
    model_param_dim = sum(p.numel() for p in init_model.parameters())
    
    # ä¸ºæ¯ä¸ªæ¨¡å¼ç”Ÿæˆå”¯ä¸€çš„æŠ•å½±çŸ©é˜µæ–‡ä»¶åˆ°projæ–‡ä»¶å¤¹
    matrix_file_path = f"proj/projection_matrix_{dataset_type}.pt"
    server = Server(init_model, detection_method=detection_method, seed=seed)
    server.generate_projection_matrix(model_param_dim, min(1024, model_param_dim), matrix_file_path)

    # é€‰æ‹©æŠ•æ¯’å®¢æˆ·ç«¯
    poison_client_ids = random.sample(
        range(config['total_clients']), 
        int(config['total_clients'] * config['poison_ratio'])
    )
    ATTACK_TYPES = config['attack_types']  # ä»é…ç½®è·å–æ”»å‡»ç±»å‹åˆ—è¡¨

    # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆåº”ç”¨é€‰å®šçš„æ”»å‡»ç±»å‹ï¼‰
    all_clients = []
    attack_type_idx = 0
    # æ”»å‡»å‚æ•°æ˜ å°„è¡¨ï¼ˆä¸poison_loader.pyå¯¹åº”ï¼‰
    attack_params_map = {
        "random_poison": {"noise_std": 0.5},
        "label_flip": {"flip_ratio": 1},
        "model_compress": {"compress_ratio": 0.95},
        "backdoor": {"backdoor_ratio": 0.08, "backdoor_target": 9, "trigger_size": 2},
        "gradient_inversion": {"inversion_strength": 1000.0},
        "gradient_amplify": {"amplify_factor": 5.0},
        "feature_poison": {"poison_strength": 0.3, "perturb_dim": 100},
        "batch_poison": {"poison_ratio": 0.2, "batch_noise_std": 0.1}
    }

    for client_id in range(config['total_clients']):
        if client_id in poison_client_ids:
            # å¾ªç¯åˆ†é…æ”»å‡»ç±»å‹
            attack_type = ATTACK_TYPES[attack_type_idx % len(ATTACK_TYPES)]
            attack_type_idx += 1
            attack_params = attack_params_map[attack_type]
            poison_loader = PoisonLoader([attack_type], attack_params)
            print(f"å®¢æˆ·ç«¯{client_id}ï¼šæŠ•æ¯’æ”»å‡»ï¼ˆ{attack_type}ï¼Œå‚æ•°ï¼š{attack_params}ï¼‰")
        else:
            poison_loader = None
            print(f"å®¢æˆ·ç«¯{client_id}ï¼šæ­£å¸¸å®¢æˆ·ç«¯")

        client = Client(
            client_id=client_id,
            dataloader=all_client_dataloaders[client_id],
            model_class=model_class,
            poison_loader=poison_loader
        )
        all_clients.append(client)

    # è”é‚¦è®­ç»ƒä¸»å¾ªç¯
    accuracy_history = []
    for round_num in range(1, config['comm_rounds'] + 1):
        print(f"\n===== {mode_name} - ç¬¬{round_num}/{config['comm_rounds']}è½® =====")

        # ä¸‹å‘æ¨¡å‹å’ŒæŠ•å½±çŸ©é˜µ
        global_model_params, global_proj_matrix_path = server.send_model_and_proj()

        # é€‰æ‹©æ´»è·ƒå®¢æˆ·ç«¯
        active_client_ids = random.sample(
            range(config['total_clients']), 
            config['active_clients']
        )
        active_clients = [all_clients[i] for i in active_client_ids]

        print(f"å‚ä¸å®¢æˆ·ç«¯ï¼š{active_client_ids} | æ¶æ„å®¢æˆ·ç«¯ï¼š{[cid for cid in active_client_ids if cid in poison_client_ids]}")

        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        for client in active_clients:
            client.receive_model_and_proj(global_model_params, global_proj_matrix_path)
            trained_params, grad_flat = client.local_train()
            feature = client.extract_gradient_feature(grad_flat)
            data_size = len(client.dataloader.dataset)
            server.receive_client_data(trained_params, data_size, feature, client.client_id)

        # èšåˆ
        if detection_method == "none":
            server.aggregate_without_detection()
        else:
            server.aggregate_with_detection()

        # è¯„ä¼°
        acc = server.evaluate_model(test_loader)
        accuracy_history.append(acc)
        print(f"æœ¬è½®å‡†ç¡®ç‡: {acc:.2f}%")

        # æ¸…ç†å†…å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # æ¸…ç†æŠ•å½±çŸ©é˜µæ–‡ä»¶
    # if os.path.exists(matrix_file_path):
    #     os.remove(matrix_file_path)
    #     print(f"æŠ•å½±çŸ©é˜µæ–‡ä»¶å·²æ¸…ç†: {matrix_file_path}")

    # ä¿å­˜ç»“æœ
    save_result_with_config(
        save_dir="results",
        mode_name=mode_name,
        model_type=model_type,
        dataset_type=dataset_type,
        detection_method=detection_method,
        config=config,
        accuracy_history=accuracy_history
    )

    return np.array(accuracy_history)


# ---------------------- ä¸»è®­ç»ƒå‡½æ•° ----------------------
def main_train(
    model_type='lenet5',
    dataset_type='mnist',
    detection_method="lsh_score_kickout",
    save_dir="results",
    **kwargs
):
    """ç»Ÿä¸€çš„ä¸»è®­ç»ƒå‡½æ•°"""
    # é»˜è®¤é…ç½®
    base_config = {
        'lr': 0.01,
        'local_epochs': 5,
        'comm_rounds': 100,
        'total_clients': 20,
        'active_clients': 20,
        'poison_ratio': 0.2,
        'batch_size': 64,
        'if_noniid': False,
        'alpha': 0.1,
        'detection_method': detection_method,
        'model_type': model_type,
        'dataset_type': dataset_type,
        'attack_types': ["random_poison"],  # é»˜è®¤æ”»å‡»ç±»å‹
        'seed': 42
    }
    # è¦†ç›–é»˜è®¤é…ç½®
    base_config.update(kwargs)
    config = base_config

    print("===== è”é‚¦å­¦ä¹ æŠ•æ¯’é˜²å¾¡å®éªŒ =====")
    print(f"é…ç½®å‚æ•°ï¼š{json.dumps(config, indent=2)}")
    print(f"æ£€æµ‹æ–¹æ³•ï¼š{detection_method}")
    print(f"æ•°æ®é›†ï¼š{dataset_type} | æ¨¡å‹ï¼š{model_type}")
    print(f"ä½¿ç”¨çš„æŠ•æ¯’æ”»å‡»ç±»å‹ï¼š{config['attack_types']}")

    # å®šä¹‰è®­ç»ƒæ¨¡å¼
    modes = [
        {
            'name': 'pure_training',
            'config': {** config, 'poison_ratio': 0.0},
            'detection_method': 'none'
        },
        {
            'name': 'poison_no_detection',
            'config': {**config},
            'detection_method': 'none'
        },
        {
            'name': 'poison_with_detection',
            'config': {** config},
            'detection_method': detection_method
        }
    ]

    # è¿è¡Œæ‰€æœ‰æ¨¡å¼
    all_results = {}
    for mode in modes:
        print(f"\n=== å¼€å§‹è®­ç»ƒï¼š{mode['name']} ===")
        acc_history = run_single_mode(
            model_type=model_type,
            dataset_type=dataset_type,
            config=mode['config'],
            mode_name=mode['name'],
            detection_method=mode['detection_method'],
            seed=config['seed']
        )
        all_results[mode['name']] = acc_history

    # å¯è§†åŒ–å¯¹æ¯”ç»“æœ
    plot_comparison_curves(
        base_config,
        result_dir=save_dir,
        save_path=os.path.join(save_dir, f"comparison_{detection_method}_{base_config['if_noniid']}_{base_config['attack_types']}_{base_config['poison_ratio']}.png")
    )

    # è¾“å‡ºæ€»ç»“
    print("\n===== è®­ç»ƒæ€»ç»“ =====")
    for mode_name, acc_history in all_results.items():
        final_acc = acc_history[-1]
        max_acc = np.max(acc_history)
        avg_acc = np.mean(acc_history)
        print(f"{mode_name}:")
        print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {final_acc:.2f}% | æœ€é«˜å‡†ç¡®ç‡: {max_acc:.2f}% | å¹³å‡å‡†ç¡®ç‡: {avg_acc:.2f}%")

    return all_results

# ---------------------- è¿è¡Œå…¥å£ ----------------------
if __name__ == "__main__":
    # æ‰“å°æ£€æµ‹æ–¹æ³•é€‰é¡¹
    print("===== è”é‚¦å­¦ä¹ æŠ•æ¯’é˜²å¾¡å®éªŒ =====")
    # æ£€æµ‹æ–¹æ³•è®¾ç½®
    # å¯é€‰æ£€æµ‹æ–¹æ³•ï¼š
    # 1. "none" - æ— æ£€æµ‹ï¼ˆçº¯FedAvgï¼‰
    # 2. "lsh_score_kickout" - LSH+ä¸‰å±‚æ‰“åˆ†+å‰”é™¤ï¼ˆé»˜è®¤ï¼‰
    # 3. "only_score" - ä»…æ‰“åˆ†ä¸å‰”é™¤
    # 4. "only_kickout" - ä»…å‰”é™¤ä¸æ‰“åˆ†
    detection_method = "lsh_score_kickout"  # æ­¤å¤„è®¾ç½®æ£€æµ‹æ–¹æ³•


    # æŠ•æ¯’æ”»å‡»ç±»å‹è®¾ç½®
    # å¯é€‰æŠ•æ¯’æ”»å‡»ç±»å‹ï¼ˆå¯å¤šé€‰ï¼Œå¡«å†™æ”»å‡»åç§°å­—ç¬¦ä¸²ï¼‰ï¼š
    # 1. "random_poison"
    # 2. "label_flip"
    # 3. "model_compress"
    # 4. "backdoor"
    # 5. "gradient_inversion"
    # 6. "gradient_amplify"
    # 7. "feature_poison"
    # 8. "batch_poison"
    selected_attacks = ["random_poison"]
    
    # ç¡®ä¿è‡³å°‘é€‰æ‹©ä¸€ç§æ”»å‡»ç±»å‹ï¼ˆå¦‚æœæŠ•æ¯’æ¯”ä¾‹>0ï¼‰
    if not selected_attacks:
        print("æœªé€‰æ‹©æ”»å‡»ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨random_poison")
        selected_attacks = ["random_poison"]
    
    # è¿è¡Œä¸»è®­ç»ƒå‡½æ•°
    results = main_train(
        model_type='cifar10',
        dataset_type='cifar10',
        detection_method=detection_method,
        comm_rounds=300,
        poison_ratio=0.2,
        attack_types=selected_attacks,  # ä¼ å…¥é€‰å®šçš„æ”»å‡»ç±»å‹
        if_noniid=True,
        seed=42
    )
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ results ç›®å½•")



